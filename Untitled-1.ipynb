{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import pathlib\n",
    "import urllib.parse\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "from shapely.geometry import shape\n",
    "\n",
    "import sqlalchemy as db\n",
    "import sqlalchemy.dialects.postgresql as pg\n",
    "import hashlib\n",
    "\n",
    "from sqlalchemy.orm import declarative_base\n",
    "from geoalchemy2.types import Geometry\n",
    "from geoalchemy2.shape import from_shape\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "from shapely.wkb import loads as wkb_loads\n",
    "import geoplot as gplt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import warnings\n",
    "\n",
    "import os\n",
    "# data prepare\n",
    "# Where data files will be read from/written to - this should already exist\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "\n",
    "# ZIPCODE_DATA_FILE = DATA_DIR / \"zipcodes\" / \"ZIP_CODE_040114.shp\"\n",
    "ZIPCODE_DATA_FILE = DATA_DIR / \"nyc_zipcodes.shp\"\n",
    "\n",
    "ZILLOW_DATA_FILE = DATA_DIR / \"zillow_rent_data.csv\"\n",
    "\n",
    "NYC_DATA_APP_TOKEN = \"EqSebYPKeoZPWmssyC2rvIPN8\"\n",
    "BASE_NYC_DATA_URL = \"https://data.cityofnewyork.us/\"\n",
    "NYC_DATA_311 = \"erm2-nwe9.geojson\"\n",
    "NYC_DATA_TREES = \"5rq2-4hqu.geojson\"\n",
    "\n",
    "DB_NAME = \"apartment\"\n",
    "DB_USER = \"postgres\"\n",
    "DB_URL = f\"postgresql+psycopg2://{DB_USER}@localhost/{DB_NAME}\"\n",
    "DB_SCHEMA_FILE = \"schema.sql\"\n",
    "# directory where DB queries for Part 3 will be saved\n",
    "QUERY_DIR = pathlib.Path(\"queries\")\n",
    "\n",
    "BASIC_USER = 'bo8yv64rbrt1cas4iyua598vp'\n",
    "BASIC_PASS = '5vwh31bomglif6wi66lb1py390txqu57vkgv8319f2kg1hxkuk'\n",
    "\n",
    "\n",
    "# When FLAG_DEBUG == True, record size will be limited to 100,000\n",
    "FLAG_DEBUG = False\n",
    "\n",
    "# Make sure the QUERY_DIRECTORY exists\n",
    "if not QUERY_DIR.exists():\n",
    "    QUERY_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avoid_nan(value):\n",
    "    \"\"\"Replace NaN in a cell with None to avoid errors when saving to the database\"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "\n",
    "def debug_warp(count:int):\n",
    "    \"\"\"When FLAG_DEBUG is True, limit record size to 10000\"\"\"\n",
    "    if FLAG_DEBUG:\n",
    "        return 100000\n",
    "    else:\n",
    "        return count\n",
    "\n",
    "\n",
    "def build_query_url(base_url: str, queries: dict = {}, flag_use_token: bool = True):\n",
    "    \"\"\"Build queries into url query string, and add api token to url\"\"\"\n",
    "    result = base_url[:] + \"?\"\n",
    "\n",
    "    if flag_use_token:\n",
    "        result += f\"$$app_token={NYC_DATA_APP_TOKEN}&\"\n",
    "\n",
    "    for key in queries:\n",
    "        result += f\"{key}={queries[key]}&\"\n",
    "\n",
    "    return result[:-1]\n",
    "\n",
    "\n",
    "def get_md5(content: str):\n",
    "    \"\"\"Calculate the md5 of a string\"\"\"\n",
    "    if isinstance(content, str):\n",
    "        content = content.encode()\n",
    "    md5 = hashlib.md5()\n",
    "    md5.update(content)\n",
    "    return md5.hexdigest()\n",
    "\n",
    "\n",
    "def get_with_cache(url: str, update: bool = False):\n",
    "    \"\"\"This function implements a get function with Cache\"\"\"\n",
    "    url_md5 = get_md5(url)\n",
    "    storage_path = DATA_DIR / url_md5\n",
    "\n",
    "    print('update or (not storage_path.exists()):',\n",
    "          update or (not storage_path.exists()))\n",
    "\n",
    "    if update or (not storage_path.exists()):\n",
    "        print(f\"Downloading {url} ...\")\n",
    "\n",
    "        session = requests.Session()\n",
    "        # session.headers.update({\"X-App-Token\": NYC_DATA_APP_TOKEN})\n",
    "        basic = requests.auth.HTTPBasicAuth(BASIC_USER, BASIC_PASS)\n",
    "\n",
    "        count = 5\n",
    "\n",
    "        while count >= 0:\n",
    "            response = None\n",
    "            print(f'Download try: {5 + 1 - count}')\n",
    "            try:\n",
    "                response = session.get(url, auth=basic)\n",
    "            except Exception:\n",
    "                print('Network error, retry')\n",
    "                count -= 1\n",
    "                continue\n",
    "\n",
    "            if response:\n",
    "                with open(storage_path, \"wb\") as file_handle:\n",
    "                    file_handle.write(response.content)\n",
    "                print(f\"Done downloading {url}.\")\n",
    "                break\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Download {url} fail, reason:\",\n",
    "                    response.status_code,\n",
    "                    \"message:\",\n",
    "                    response.content.decode(),\n",
    "                )\n",
    "                continue\n",
    "\n",
    "    return storage_path\n",
    "\n",
    "\n",
    "def download_nyc_geojson_data(url: str, force: bool = False):\n",
    "    \"\"\"This function is deprecated because it doesn't support url with query's very well\"\"\"\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    url_path = parsed_url.path.strip(\"/\")\n",
    "\n",
    "    filename = DATA_DIR / url_path\n",
    "\n",
    "    if force or not filename.exists():\n",
    "        print(f\"Downloading {url} to {filename}...\")\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response:\n",
    "            with open(filename, \"w\") as file_handle:\n",
    "                # json.dump(..., f)\n",
    "                file_handle.write(response.content)\n",
    "            print(f\"Done downloading {url}.\")\n",
    "        else:\n",
    "            print(f\"Download {url} fail.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Reading from {filename}...\")\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zipcodes(zipcode_datafile) :\n",
    "    \"\"\"Loading and cleaning the zip code dataset\"\"\"\n",
    "\n",
    "    gdf = gpd.read_file(zipcode_datafile)\n",
    "\n",
    "    mapping_k = ['ZIPCODE', 'PO_NAME', 'STATE', 'COUNTY', 'geometry']\n",
    "\n",
    "    mapping_v = ['zipcode', 'neighborhood', 'state', 'county', 'geometry']\n",
    "\n",
    "    name_mapping = dict(map(lambda value_key, value_value: (value_key, value_value), mapping_k, mapping_v))\n",
    "\n",
    "    gdf.crs = 'epsg:2263'\n",
    "\n",
    "    gdf = gdf.to_crs('epsg:4326')\n",
    "\n",
    "    # result = pd.DataFrame(gdf)\n",
    "    result = gdf\n",
    "\n",
    "    column_to_delete = []\n",
    "\n",
    "    for column_name in result.columns:\n",
    "\n",
    "        if column_name not in mapping_k:\n",
    "\n",
    "            column_to_delete.append(column_name)\n",
    "\n",
    "    result = result.drop(column_to_delete, axis=1)\n",
    "\n",
    "    result = result.rename(columns=name_mapping)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def download_and_clean_311_data():\n",
    "    \"\"\"Loading and Cleaning 311 Complaint Data Set\"\"\"\n",
    "    # https://data.cityofnewyork.us/resource/erm2-nwe9.json\n",
    "\n",
    "    params = {\n",
    "        '$select': 'count(unique_key)',\n",
    "        # '$where': 'complaint_type LIKE \"%25Noise%25\" AND created_date >= \"2022-01-01T00:00:00\"::floating_timestamp',\n",
    "        '$where': 'created_date >= \"2022-01-01T00:00:00\"::floating_timestamp',\n",
    "    }\n",
    "\n",
    "    query_url = build_query_url(\n",
    "        'https://data.cityofnewyork.us/resource/erm2-nwe9.json', params, False)\n",
    "\n",
    "    print('Will call get_with_cache() ... 1')\n",
    "    dataset_path = get_with_cache(query_url, update=False)\n",
    "    print('     Call get_with_cache() ... 1 ... end')\n",
    "\n",
    "    jsonStr = '[]'\n",
    "\n",
    "    with open(dataset_path, 'rb') as file_handle:\n",
    "        jsonStr = file_handle.read().decode()\n",
    "\n",
    "    row_count_since_20220101 = debug_warp(\n",
    "        int(json.loads(jsonStr)[0]['count_unique_key']))\n",
    "\n",
    "    query_url = build_query_url(\n",
    "        'https://data.cityofnewyork.us/resource/erm2-nwe9.json', params, False)\n",
    "\n",
    "    collected_row_count = 0\n",
    "\n",
    "    result = gpd.GeoDataFrame()\n",
    "\n",
    "    print(f'Report {collected_row_count} / {row_count_since_20220101} ...')\n",
    "\n",
    "    while collected_row_count < row_count_since_20220101:\n",
    "\n",
    "        print(\n",
    "            f'Collect {collected_row_count} / {row_count_since_20220101} ...')\n",
    "\n",
    "        params = {\n",
    "            '$select': 'unique_key, created_date, complaint_type, incident_zip, latitude, longitude',\n",
    "            # '$where': 'complaint_type LIKE \"%25Noise%25\" AND created_date >= \"2022-01-01T00:00:00\"::floating_timestamp',\n",
    "            '$where': 'created_date >= \"2022-01-01T00:00:00\"::floating_timestamp',\n",
    "            '$limit': '150000',\n",
    "            '$offset': collected_row_count\n",
    "        }\n",
    "\n",
    "        query_url = build_query_url(\n",
    "            'https://data.cityofnewyork.us/resource/erm2-nwe9.json', params, False)\n",
    "\n",
    "        print('Will call get_with_cache() ... 2')\n",
    "        dataset_path = get_with_cache(query_url)\n",
    "\n",
    "        jsonStr = '[]'\n",
    "\n",
    "        with open(dataset_path, 'rb') as file_handle:\n",
    "            jsonStr = file_handle.read().decode()\n",
    "\n",
    "        jsonObject = json.loads(jsonStr)\n",
    "\n",
    "        part_dataframe = pd.DataFrame.from_records(jsonObject)\n",
    "\n",
    "        result = pd.concat([result, part_dataframe], ignore_index=True)\n",
    "\n",
    "        collected_row_count += len(jsonObject)\n",
    "\n",
    "    result['incident_zip'].fillna(value=-1, inplace=True)\n",
    "    result['geometry'] = gpd.points_from_xy(\n",
    "        result['longitude'], result['latitude'])\n",
    "    result = result.drop(['latitude', 'longitude'], axis=1)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_clean_tree_data():\n",
    "    \"\"\"Load and clean the tree dataset\"\"\"\n",
    "\n",
    "    # https://data.cityofnewyork.us/resource/5rq2-4hqu.json\n",
    "\n",
    "    # [\"tree_id\", \"spc_common\", \"zipcode\", \"status\", \"the_geom\"]\n",
    "\n",
    "    params = {\n",
    "        \"$select\": \"count(tree_id)\"\n",
    "    }\n",
    "\n",
    "    query_url = build_query_url(\n",
    "        \"https://data.cityofnewyork.us/resource/5rq2-4hqu.json\", params, False\n",
    "    )\n",
    "\n",
    "    dataset_path = get_with_cache(query_url, update=False)\n",
    "\n",
    "    jsonStr = \"[]\"\n",
    "\n",
    "    with open(dataset_path, \"rb\") as file_handle:\n",
    "\n",
    "        jsonStr = file_handle.read().decode()\n",
    "\n",
    "    row_count = debug_warp(int(json.loads(jsonStr)[0][\"count_tree_id\"]))\n",
    "\n",
    "    collected_row_count = 0\n",
    "\n",
    "    result = gpd.GeoDataFrame()\n",
    "\n",
    "    while collected_row_count < row_count:\n",
    "\n",
    "        print(f\"Collect {collected_row_count} / {row_count} ...\")\n",
    "\n",
    "        params = {\n",
    "            \"$select\": \"tree_id, spc_common, zipcode, status, health, the_geom\",\n",
    "            \"$limit\": \"150000\",\n",
    "            \"$offset\": collected_row_count,\n",
    "        }\n",
    "\n",
    "        query_url = build_query_url(\n",
    "            \"https://data.cityofnewyork.us/resource/5rq2-4hqu.json\", params, False\n",
    "        )\n",
    "\n",
    "        dataset_path = get_with_cache(query_url)\n",
    "\n",
    "        jsonStr = \"[]\"\n",
    "\n",
    "        with open(dataset_path, \"rb\") as file_handle:\n",
    "\n",
    "            jsonStr = file_handle.read().decode()\n",
    "\n",
    "        jsonObject = json.loads(jsonStr)\n",
    "\n",
    "        part_dataframe = pd.DataFrame.from_records(jsonObject)\n",
    "\n",
    "        result = pd.concat([result, part_dataframe], ignore_index=True)\n",
    "\n",
    "        collected_row_count += len(jsonObject)\n",
    "\n",
    "    result = result.rename(columns={\"the_geom\": \"geometry\"})\n",
    "\n",
    "    result['geometry'] = result['geometry'].apply(shape)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_zillow_data():\n",
    "    \"\"\"Load and clean historical rental dataset\"\"\"\n",
    "\n",
    "    df = pd.read_csv(ZILLOW_DATA_FILE)\n",
    "\n",
    "    df = df.drop(['RegionID', 'SizeRank', 'RegionType', 'StateName',\n",
    "                 'City', 'Metro', 'CountyName'], axis=1)\n",
    "\n",
    "    df = df.rename(columns={'RegionName': 'zipcode'})\n",
    "\n",
    "    columns = df.columns\n",
    "\n",
    "    columns = columns[2:]\n",
    "\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    values = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        for column in columns:\n",
    "\n",
    "            new_row = {\n",
    "\n",
    "                'zipcode': row['zipcode'],\n",
    "\n",
    "                'state': row['State'],\n",
    "\n",
    "                'date': column,\n",
    "\n",
    "                'average_price': row[column]\n",
    "\n",
    "            }\n",
    "\n",
    "            values.append(new_row)\n",
    "\n",
    "    result = pd.DataFrame.from_records(values)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"Load all data\"\"\"\n",
    "\n",
    "    geodf_zipcode_data = load_and_clean_zipcodes(ZIPCODE_DATA_FILE)\n",
    "\n",
    "    geodf_311_data = download_and_clean_311_data()\n",
    "\n",
    "    geodf_tree_data = download_and_clean_tree_data()\n",
    "\n",
    "    df_zillow_data = load_and_clean_zillow_data()\n",
    "\n",
    "    return (geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will call get_with_cache() ... 1\n",
      "update or (not storage_path.exists()): False\n",
      "     Call get_with_cache() ... 1 ... end\n",
      "Report 0 / 6199520 ...\n",
      "Collect 0 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 150000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 300000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 450000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 600000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 750000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 900000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1050000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1200000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1350000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1500000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1650000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1800000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 1950000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2100000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2250000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2400000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2550000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2700000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 2850000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3000000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3150000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3300000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3450000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3600000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3750000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 3900000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4050000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4200000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4350000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4500000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4650000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4800000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 4950000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5100000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5250000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5400000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5550000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5700000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 5850000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 6000000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 6150000 / 6199520 ...\n",
      "Will call get_with_cache() ... 2\n",
      "update or (not storage_path.exists()): False\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 0 / 683788 ...\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 150000 / 683788 ...\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 300000 / 683788 ...\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 450000 / 683788 ...\n",
      "update or (not storage_path.exists()): False\n",
      "Collect 600000 / 683788 ...\n",
      "update or (not storage_path.exists()): False\n"
     ]
    }
   ],
   "source": [
    "geodf_zipcode_data, geodf_311_data, geodf_tree_data, df_zillow_data = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'geopandas.geodataframe.GeoDataFrame'>\n",
      "RangeIndex: 263 entries, 0 to 262\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype   \n",
      "---  ------        --------------  -----   \n",
      " 0   zipcode       263 non-null    object  \n",
      " 1   neighborhood  263 non-null    object  \n",
      " 2   state         263 non-null    object  \n",
      " 3   county        263 non-null    object  \n",
      " 4   geometry      263 non-null    geometry\n",
      "dtypes: geometry(1), object(4)\n",
      "memory usage: 10.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11436</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>NY</td>\n",
       "      <td>Queens</td>\n",
       "      <td>POLYGON ((-73.80585 40.68291, -73.80569 40.682...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11213</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.93740 40.67973, -73.93487 40.679...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11212</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.90294 40.67084, -73.90223 40.668...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11225</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.95797 40.67066, -73.95576 40.670...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11218</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>NY</td>\n",
       "      <td>Kings</td>\n",
       "      <td>POLYGON ((-73.97208 40.65060, -73.97192 40.650...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zipcode neighborhood state  county  \\\n",
       "0   11436      Jamaica    NY  Queens   \n",
       "1   11213     Brooklyn    NY   Kings   \n",
       "2   11212     Brooklyn    NY   Kings   \n",
       "3   11225     Brooklyn    NY   Kings   \n",
       "4   11218     Brooklyn    NY   Kings   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-73.80585 40.68291, -73.80569 40.682...  \n",
       "1  POLYGON ((-73.93740 40.67973, -73.93487 40.679...  \n",
       "2  POLYGON ((-73.90294 40.67084, -73.90223 40.668...  \n",
       "3  POLYGON ((-73.95797 40.67066, -73.95576 40.670...  \n",
       "4  POLYGON ((-73.97208 40.65060, -73.97192 40.650...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_zipcode_data.info()\n",
    "geodf_zipcode_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6199520 entries, 0 to 6199519\n",
      "Data columns (total 5 columns):\n",
      " #   Column          Dtype   \n",
      "---  ------          -----   \n",
      " 0   unique_key      object  \n",
      " 1   created_date    object  \n",
      " 2   complaint_type  object  \n",
      " 3   incident_zip    object  \n",
      " 4   geometry        geometry\n",
      "dtypes: geometry(1), object(4)\n",
      "memory usage: 236.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59681385</td>\n",
       "      <td>2023-12-09T12:00:00.000</td>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>11222</td>\n",
       "      <td>POINT (-73.94549 40.71914)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59682706</td>\n",
       "      <td>2023-12-09T12:00:00.000</td>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>11412</td>\n",
       "      <td>POINT (-73.75719 40.69898)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59683999</td>\n",
       "      <td>2023-12-09T12:00:00.000</td>\n",
       "      <td>Derelict Vehicles</td>\n",
       "      <td>11357</td>\n",
       "      <td>POINT (-73.82518 40.77956)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59681790</td>\n",
       "      <td>2023-12-09T02:41:46.000</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>10032</td>\n",
       "      <td>POINT (-73.94337 40.83670)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59684401</td>\n",
       "      <td>2023-12-09T02:06:35.000</td>\n",
       "      <td>Graffiti</td>\n",
       "      <td>11211</td>\n",
       "      <td>POINT (-73.95151 40.71341)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_key             created_date     complaint_type incident_zip  \\\n",
       "0   59681385  2023-12-09T12:00:00.000  Derelict Vehicles        11222   \n",
       "1   59682706  2023-12-09T12:00:00.000  Derelict Vehicles        11412   \n",
       "2   59683999  2023-12-09T12:00:00.000  Derelict Vehicles        11357   \n",
       "3   59681790  2023-12-09T02:41:46.000           Graffiti        10032   \n",
       "4   59684401  2023-12-09T02:06:35.000           Graffiti        11211   \n",
       "\n",
       "                     geometry  \n",
       "0  POINT (-73.94549 40.71914)  \n",
       "1  POINT (-73.75719 40.69898)  \n",
       "2  POINT (-73.82518 40.77956)  \n",
       "3  POINT (-73.94337 40.83670)  \n",
       "4  POINT (-73.95151 40.71341)  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_311_data.info()\n",
    "geodf_311_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 683788 entries, 0 to 683787\n",
      "Data columns (total 6 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   tree_id     683788 non-null  object\n",
      " 1   spc_common  652169 non-null  object\n",
      " 2   zipcode     683788 non-null  object\n",
      " 3   status      683788 non-null  object\n",
      " 4   health      652172 non-null  object\n",
      " 5   geometry    683788 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 31.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>spc_common</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>status</th>\n",
       "      <th>health</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180683</td>\n",
       "      <td>red maple</td>\n",
       "      <td>11375</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>POINT (-73.84421521958048 40.723091773924274)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200540</td>\n",
       "      <td>pin oak</td>\n",
       "      <td>11357</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Fair</td>\n",
       "      <td>POINT (-73.81867945834878 40.79411066708779)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>204026</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>POINT (-73.93660770459083 40.717580740099116)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204337</td>\n",
       "      <td>honeylocust</td>\n",
       "      <td>11211</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>POINT (-73.93445615919741 40.713537494833226)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>189565</td>\n",
       "      <td>American linden</td>\n",
       "      <td>11215</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Good</td>\n",
       "      <td>POINT (-73.97597938483258 40.66677775537875)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tree_id       spc_common zipcode status health  \\\n",
       "0  180683        red maple   11375  Alive   Fair   \n",
       "1  200540          pin oak   11357  Alive   Fair   \n",
       "2  204026      honeylocust   11211  Alive   Good   \n",
       "3  204337      honeylocust   11211  Alive   Good   \n",
       "4  189565  American linden   11215  Alive   Good   \n",
       "\n",
       "                                        geometry  \n",
       "0  POINT (-73.84421521958048 40.723091773924274)  \n",
       "1   POINT (-73.81867945834878 40.79411066708779)  \n",
       "2  POINT (-73.93660770459083 40.717580740099116)  \n",
       "3  POINT (-73.93445615919741 40.713537494833226)  \n",
       "4   POINT (-73.97597938483258 40.66677775537875)  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geodf_tree_data.info()\n",
    "geodf_tree_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 705810 entries, 0 to 705809\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   zipcode        705810 non-null  int64  \n",
      " 1   state          705810 non-null  object \n",
      " 2   date           705810 non-null  object \n",
      " 3   average_price  250167 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 21.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date</th>\n",
       "      <th>average_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>2015-01-31</td>\n",
       "      <td>1606.206406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>2015-02-28</td>\n",
       "      <td>1612.779844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>1622.201575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>2015-04-30</td>\n",
       "      <td>1630.392427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77494</td>\n",
       "      <td>TX</td>\n",
       "      <td>2015-05-31</td>\n",
       "      <td>1632.411500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode state        date  average_price\n",
       "0    77494    TX  2015-01-31    1606.206406\n",
       "1    77494    TX  2015-02-28    1612.779844\n",
       "2    77494    TX  2015-03-31    1622.201575\n",
       "3    77494    TX  2015-04-30    1630.392427\n",
       "4    77494    TX  2015-05-31    1632.411500"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zillow_data.info()\n",
    "df_zillow_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Storing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create database and enable PostGIS extension using command-line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE EXTENSION\n"
     ]
    }
   ],
   "source": [
    "os.environ['PGPASSWORD'] = 'postgres'\n",
    "!createdb -U postgres apartment\n",
    "!psql -U postgres --dbname apartment -c \"CREATE EXTENSION postgis;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define table model using SQLAlchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "\n",
    "class Tree(Base):\n",
    "    '''table Tree'''\n",
    "    \n",
    "    __tablename__ = \"tree\"\n",
    "\n",
    "    tree_id = db.Column(pg.INTEGER, autoincrement=False, primary_key=True)\n",
    "    spc_common = db.Column(pg.TEXT, nullable=False)\n",
    "    zipcode = db.Column(pg.INTEGER, index=True, nullable=False)\n",
    "    status = db.Column(pg.TEXT, nullable=False)\n",
    "    health = db.Column(pg.TEXT, nullable=False)\n",
    "    geometry = db.Column(Geometry(geometry_type='POINT',\n",
    "                         srid='4326'), index=True, nullable=False)\n",
    "\n",
    "\n",
    "class Complaint(Base):\n",
    "    '''table Complaint'''\n",
    "\n",
    "    __tablename__ = 'complaint'\n",
    "\n",
    "    unique_key = db.Column(pg.INTEGER, index=True,\n",
    "                           autoincrement=False, primary_key=True)\n",
    "    created_date = db.Column(pg.TIMESTAMP, index=True, nullable=False)\n",
    "    complaint_type = db.Column(pg.TEXT, index=True, nullable=False)\n",
    "    zipcode = db.Column(pg.INTEGER, index=True, nullable=True)\n",
    "    geometry = db.Column(Geometry(geometry_type='POINT',\n",
    "                         srid='4326'), index=True, nullable=False)\n",
    "\n",
    "\n",
    "class Zipcode(Base):\n",
    "    '''table Zipcode'''\n",
    "\n",
    "    __tablename__ = 'zipcode'\n",
    "\n",
    "    unique_key = db.Column(pg.INTEGER, autoincrement=True, primary_key=True)\n",
    "    zipcode = db.Column(pg.INTEGER, index=True)\n",
    "    neighborhood = db.Column(pg.TEXT, nullable=False)\n",
    "    state = db.Column(pg.TEXT, nullable=False)\n",
    "    county = db.Column(pg.TEXT, nullable=False)\n",
    "    geometry = db.Column(Geometry(geometry_type='POLYGON',\n",
    "                         srid='4326'), index=False, nullable=False)\n",
    "\n",
    "\n",
    "class Rent(Base):\n",
    "    '''table Rent'''\n",
    "\n",
    "    __tablename__ = 'rent'\n",
    "\n",
    "    unique_key = db.Column(pg.INTEGER, autoincrement=True, primary_key=True)\n",
    "    zipcode = db.Column(pg.INTEGER, nullable=False)\n",
    "    state = db.Column(pg.TEXT, nullable=False)\n",
    "    date = db.Column(pg.DATE, nullable=False)\n",
    "    average_price = db.Column(pg.FLOAT, nullable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "#### Option 2: SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup database session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Session = db.orm.sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insert dataframe's data to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will insert to table: tree. Rows to insert: 683788\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Will insert to table: tree. Rows to insert:', len(geodf_tree_data.index))\n",
    "\n",
    "gis_geodf_tree_data = gpd.GeoDataFrame(geodf_tree_data, crs='epsg:4326')\n",
    "\n",
    "gis_geodf_tree_data.to_postgis(\n",
    "    name='tree', if_exists='replace', con=engine, dtype={'zipcode': pg.INTEGER})\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will insert to table: complaint. Rows to insert: 6199520\n"
     ]
    }
   ],
   "source": [
    "geodf_311_data = geodf_311_data[geodf_311_data['incident_zip'].notna()]\n",
    "\n",
    "geodf_311_data['zipcode'] = geodf_311_data['incident_zip']\n",
    "\n",
    "\n",
    "geodf_311_data = geodf_311_data.drop('incident_zip', axis=1)\n",
    "\n",
    "print('Will insert to table: complaint. Rows to insert:', len(geodf_311_data.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_int(value):\n",
    "    '''Check if value is int, if so, return value, otherwise return -1'''\n",
    "\n",
    "    try:\n",
    "\n",
    "        int(value)\n",
    "\n",
    "    except Exception:\n",
    "\n",
    "        return -1\n",
    "    return value\n",
    "\n",
    "geodf_311_data['zipcode'] = geodf_311_data['zipcode'].apply(check_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "gis = gpd.GeoDataFrame(geodf_311_data, crs='epsg:4326')\n",
    "\n",
    "gis.to_postgis(name='complaint', if_exists='replace', con=engine, dtype={\n",
    "               'unique_key': pg.INTEGER, 'created_date': pg.TIMESTAMP, 'zipcode': pg.INTEGER})\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in geodf_zipcode_data.iterrows():\n",
    "    zipcode = Zipcode(zipcode=row['zipcode'], neighborhood=row['neighborhood'], state=row['state'],\n",
    "                      county=row['county'], geometry=from_shape(row['geometry'], srid=4326))\n",
    "    session.add(zipcode)\n",
    "try:\n",
    "    session.commit()\n",
    "except Exception as sql_exception:\n",
    "    session.rollback()\n",
    "    print()\n",
    "    print(sql_exception, ':')\n",
    "    print(row)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will insert to table: rent. Rows to insert: 705810\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print('Will insert to table: rent. Rows to insert:', len(df_zillow_data.index))\n",
    "\n",
    "df_zillow_data.to_sql(name='rent', if_exists='replace', con=engine, dtype={\n",
    "                      'unique_key': pg.INTEGER, 'zipcode': pg.INTEGER, 'date': pg.DATE, 'average_price': pg.FLOAT})\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
